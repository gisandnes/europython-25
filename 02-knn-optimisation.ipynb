{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a7f01ae3",
      "metadata": {
        "id": "a7f01ae3"
      },
      "source": [
        "# KNN Optimisation\n",
        "\n",
        "We will explore how to optimise performance using [JAX](https://docs.jax.dev) and [Numba](https://numba.pydata.org/).\n",
        "Our goal will be to optimise the performance of a k-nearest neighbours (kNN) search.\n",
        "We will not focus on the algorithm itself, or the data, but rather on the performance of the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4da720",
      "metadata": {
        "id": "df4da720"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d434d95",
      "metadata": {
        "id": "2d434d95"
      },
      "source": [
        "## kNN Search Algorithm\n",
        "\n",
        "We will use the kNN search (and later the kNN regressor) as a running example.\n",
        "\n",
        "### kNN Search\n",
        "\n",
        "The kNN search is a simple algorithm that finds the k nearest neighbours of a query point in a dataset.\n",
        "It can be described as follows:\n",
        "\n",
        "1. Calculate the distance between the query point and all points in the dataset.\n",
        "2. Sort the distances and find the k smallest distances.\n",
        "3. Return the indices of the k smallest distances."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de5bdb23",
      "metadata": {
        "id": "de5bdb23"
      },
      "source": [
        "### Numpy implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11f4c9a",
      "metadata": {
        "id": "f11f4c9a"
      },
      "outputs": [],
      "source": [
        "def euclidean_distances_numpy(query_points: np.ndarray, dataset: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Calculate Euclidean distances between all query points and all dataset points using NumPy.\n",
        "\n",
        "    We consider the input arrays to be in the shape of (n_points, n_dimensions).\n",
        "\n",
        "    Args:\n",
        "        query_points (np.ndarray): Query points (2D array).\n",
        "        dataset (np.ndarray): Dataset of reference points (2D array).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Euclidean distances between query points and dataset points.\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.sum((dataset[:, np.newaxis, :] - query_points) ** 2, axis=-1))\n",
        "\n",
        "\n",
        "def knn_search_numpy(\n",
        "    query_points: np.ndarray,\n",
        "    dataset: np.ndarray,\n",
        "    k: int,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Finds the k nearest neighbors for a single query point using NumPy.\n",
        "\n",
        "    Args:\n",
        "        query_points (np.ndarray): Query points (2D array).\n",
        "        dataset (np.ndarray): Dataset of reference points (2D array).\n",
        "        k (int): The number of neighbors to find.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Indices of the k nearest neighbors in the dataset.\n",
        "    \"\"\"\n",
        "    distances = euclidean_distances_numpy(query_points, dataset)\n",
        "\n",
        "    # Find the indices of the k smallest distances\n",
        "    nearest_indices = np.argpartition(distances, k, axis=0)[:k].T\n",
        "\n",
        "    return nearest_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da17522b",
      "metadata": {
        "id": "da17522b"
      },
      "source": [
        "### Helper plotting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e58d71",
      "metadata": {
        "id": "b4e58d71"
      },
      "outputs": [],
      "source": [
        "def visualise_knn(query_points: np.ndarray, dataset: np.ndarray, neighbours: np.ndarray) -> go.Figure:\n",
        "    # Plot all data points\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=dataset[:, 0],\n",
        "            y=dataset[:, 1],\n",
        "            mode=\"markers\",\n",
        "            marker=dict(size=8, color=\"lightgrey\"),\n",
        "            name=\"Dataset Points\",\n",
        "        )\n",
        "    )\n",
        "\n",
        "    show_legend = True\n",
        "    for query_point, point_neighbours in zip(query_points, neighbours):\n",
        "        # Plot the query point\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=[query_point[0]],\n",
        "                y=[query_point[1]],\n",
        "                mode=\"markers\",\n",
        "                marker=dict(size=14, color=\"red\", symbol=\"x\"),\n",
        "                name=\"Query Point\",\n",
        "                showlegend=show_legend,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Draw lines from query point to each neighbour for clarity\n",
        "        for neighbour in point_neighbours:\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=[query_point[0], neighbour[0]],\n",
        "                    y=[query_point[1], neighbour[1]],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(color=\"royalblue\", dash=\"dot\"),\n",
        "                    showlegend=False,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Plot the k nearest neighbours\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=point_neighbours[:, 0],\n",
        "                y=point_neighbours[:, 1],\n",
        "                mode=\"markers\",\n",
        "                marker=dict(size=12, color=\"royalblue\", symbol=\"circle-open\"),\n",
        "                name=\"Nearest Neighbours\",\n",
        "                showlegend=show_legend,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        show_legend = False\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"kNN Search Visualisation\",\n",
        "        xaxis_title=\"Sepal Width\",\n",
        "        yaxis_title=\"Sepal Length\",\n",
        "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
        "        width=700,\n",
        "        height=500,\n",
        "        # Ensure axes have identical scales for accurate spatial interpretation\n",
        "        xaxis=dict(\n",
        "            scaleanchor=\"y\",  # Link x-axis scale to y-axis\n",
        "            scaleratio=1,     # 1:1 aspect ratio\n",
        "        ),\n",
        "        yaxis=dict(\n",
        "            constrain=\"domain\",  # Prevent stretching of y-axis\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c86b487",
      "metadata": {
        "id": "2c86b487"
      },
      "source": [
        "### Demonstration\n",
        "\n",
        "Let's demonstrate the kNN search algorithm on a simple 2D dataset. We will use the popular Iris dataset, and select just the first two features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531b32d7",
      "metadata": {
        "id": "531b32d7"
      },
      "outputs": [],
      "source": [
        "# Load a simple 2D dataset (Iris, first two features)\n",
        "dataset = px.data.iris()[[\"sepal_width\", \"sepal_length\"]].to_numpy()\n",
        "\n",
        "# Select a query point (e.g., a random point not in the dataset)\n",
        "query_points = np.array([[2.5, 6], [3.5, 7.0]])\n",
        "\n",
        "# Find k nearest neighbours using the previously defined function\n",
        "neighbour_indices = knn_search_numpy(query_points, dataset, k=3)\n",
        "neighbours = dataset[neighbour_indices]\n",
        "\n",
        "print(f\"Nearest neighbour indices: {neighbour_indices}\")\n",
        "print(f\"Nearest neighbours of {query_points}:\\n{neighbours}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe669e2",
      "metadata": {
        "id": "9fe669e2"
      },
      "outputs": [],
      "source": [
        "visualise_knn(query_points, dataset, neighbours)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f52870",
      "metadata": {
        "id": "e4f52870"
      },
      "source": [
        "### Performance\n",
        "\n",
        "Let's measure the performance (run time) of our algorithm. We will use the `%timeit` magic command to measure the time it takes to run the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe843aa",
      "metadata": {
        "id": "9fe843aa"
      },
      "outputs": [],
      "source": [
        "n_dataset_points: int = 10_000\n",
        "n_query_points: int = 100\n",
        "n_dim: int = 3\n",
        "k: int = 5\n",
        "\n",
        "\n",
        "def create_random_data(\n",
        "    n_points: int, n_dim: int, *, seed: int = 42\n",
        ") -> np.ndarray:\n",
        "    np.random.seed(seed)\n",
        "    return np.random.sample((n_points, n_dim)).astype(np.float32)\n",
        "\n",
        "dataset = create_random_data(n_dataset_points, n_dim, seed=420)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f20ee3a",
      "metadata": {
        "id": "3f20ee3a"
      },
      "outputs": [],
      "source": [
        "execution_times = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7e1169",
      "metadata": {
        "id": "2c7e1169"
      },
      "outputs": [],
      "source": [
        "for n_query_points in [100, 1000, 10000]:\n",
        "    query_points = create_random_data(n_query_points, n_dim)\n",
        "    execution_time = %timeit -o knn_search_numpy(query_points, dataset, k=k)\n",
        "    execution_times.append(\n",
        "        {\n",
        "            \"n_query_points\": n_query_points,\n",
        "            \"n_dataset_points\": n_dataset_points,\n",
        "            \"n_dim\": n_dim,\n",
        "            \"k\": k,\n",
        "            \"execution_time\": execution_time.average,\n",
        "            \"function\": \"knn_search_numpy\",\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a91ac4",
      "metadata": {
        "id": "95a91ac4"
      },
      "outputs": [],
      "source": [
        "for n_query_points in [100, 1000, 10000]:\n",
        "    query_points = create_random_data(n_query_points, n_dim)\n",
        "    execution_time = %timeit -o euclidean_distances_numpy(query_points, dataset)\n",
        "    execution_times.append(\n",
        "        {\n",
        "            \"n_query_points\": n_query_points,\n",
        "            \"n_dataset_points\": n_dataset_points,\n",
        "            \"n_dim\": n_dim,\n",
        "            \"execution_time\": execution_time.average,\n",
        "            \"function\": \"euclidean_distances_numpy\",\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea40043c",
      "metadata": {
        "id": "ea40043c"
      },
      "outputs": [],
      "source": [
        "px.line(\n",
        "    execution_times,\n",
        "    x=\"n_query_points\",\n",
        "    y=\"execution_time\",\n",
        "    title=\"Execution Time: kNN Search\",\n",
        "    labels={\"n_query_points\": \"Number of Query Points\", \"execution_time\": \"Execution Time (s)\"},\n",
        "    log_x=True,\n",
        "    log_y=True,\n",
        "    markers=True,\n",
        "    color=\"function\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7917aa2",
      "metadata": {
        "id": "d7917aa2"
      },
      "source": [
        "This is basically what we are interested in:\n",
        "- Measure the run time of a specific function.\n",
        "- See how it scales with the size of the input.\n",
        "- Compare to other functions, in this case we measure the sub-function `euclidean_distances_numpy`. We would usually do this using a profiler, such as py-spy, but in this case we can use this simple and illustrative approach.\n",
        "- Later, we will compare to other implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bbef249",
      "metadata": {
        "id": "8bbef249"
      },
      "source": [
        "## JAX Numpy and JIT\n",
        "\n",
        "[JAX Quickstart](https://docs.jax.dev/en/latest/quickstart.html):\n",
        "> JAX is a library for array-oriented numerical computation (à la NumPy), with automatic differentiation and JIT compilation to enable high-performance machine learning research.\n",
        "\n",
        "\n",
        "\n",
        "JAX provides a NumPy-compatible API (`jax.numpy`, often imported as `jnp`) that allows users to write array-based scientific code using familiar NumPy syntax. Unlike standard NumPy, JAX operations are designed to run efficiently on CPUs, GPUs, and TPUs, enabling hardware acceleration for numerical computations.\n",
        "\n",
        "A key feature of JAX is its Just-In-Time (JIT) compilation, accessed via the `jax.jit` decorator or function. JIT compilation automatically transforms Python functions into highly optimised machine code, fusing operations and reducing Python overhead. This results in substantial performance improvements, especially for large-scale or repeated computations.\n",
        "\n",
        "By combining the JAX NumPy API with JIT compilation, we can write clear, concise scientific code that is automatically optimised for modern hardware.\n",
        "\n",
        "\n",
        "### Practical example\n",
        "\n",
        "Let's demonstrate this with a simple example form the JAX documentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a01f9f9",
      "metadata": {
        "id": "1a01f9f9"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.typing import ArrayLike\n",
        "\n",
        "def selu(x: ArrayLike, alpha: float = 1.67, lmbda: float = 1.05) -> jax.Array:\n",
        "    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
        "\n",
        "\n",
        "x = jnp.arange(5.0)\n",
        "print(selu(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b054db",
      "metadata": {
        "id": "a2b054db"
      },
      "source": [
        "Note also we use `jnp.array` instead of `np.array` in the JAX version. Here, we created from scratch as a JAX array. Often, we would convert from a NumPy array.\n",
        "\n",
        "Conversion from NumPy to JAX arrays is efficient if the NumPy array is on the default device (CPU) and has a compatible dtype and memory layout—JAX will use zero-copy conversion in this case, simply wrapping the existing memory. However, if the array is not compatible (e.g., wrong dtype, not C-contiguous, or on a different device), JAX will make a copy. Thus, zero-copy is possible but not guaranteed; ensure arrays are C-contiguous and of supported dtype for best efficiency.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e19f55f",
      "metadata": {
        "id": "7e19f55f"
      },
      "outputs": [],
      "source": [
        "key = jax.random.key(1701)\n",
        "x = jax.random.normal(key, (1_000_000,))\n",
        "\n",
        "%timeit selu(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4701b92a",
      "metadata": {
        "id": "4701b92a"
      },
      "outputs": [],
      "source": [
        "selu_jit = jax.jit(selu)\n",
        "\n",
        "print(selu_jit(x)[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a569bd",
      "metadata": {
        "id": "b4a569bd"
      },
      "source": [
        "Two important things happened above:\n",
        "\n",
        "1. We instructed to Just-In-Time (JIT) compile the function when we call it.\n",
        "2. The function *was* compiled in the `print` call. It was compiled for the *concrete input type and shape*.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6c4790",
      "metadata": {
        "id": "9d6c4790"
      },
      "outputs": [],
      "source": [
        "%timeit selu_jit(x).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abab23d",
      "metadata": {
        "id": "2abab23d"
      },
      "source": [
        "The compiled function is significantly faster than the uncompiled one!\n",
        "\n",
        "Note the use of `block_until_ready`. *JAX is asynchronous by default*, and return something like futures. For timing the whole calculation, we need to wait for the result to be ready."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983c7d45",
      "metadata": {
        "id": "983c7d45"
      },
      "source": [
        "We can also empirically verify that the compilation must be done again for a different input shape, leading to an increase in the execution time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e79fd8",
      "metadata": {
        "id": "b3e79fd8"
      },
      "outputs": [],
      "source": [
        "%timeit -n 1 -r 1 selu_jit(x[:-1]).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7692fc3",
      "metadata": {
        "id": "b7692fc3"
      },
      "source": [
        "### Exercise: JIT compiling Euclidean distance\n",
        "\n",
        "1. Create a `jax.numpy` version of the Euclidean distance function `euclidean_distances_numpy`.\n",
        "2. Create a JIT-compiled version of the new function.\n",
        "3. Compare the performance of the numpy version, and the uncompiled and compiled jax version.\n",
        "4. Check that the JAX version yields the same result as the numpy version.\n",
        "\n",
        "Optionally:\n",
        "\n",
        "5. Compare the scaling of the performance of all the versions with respect to the number of query points or the number of dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0fb6d67",
      "metadata": {
        "id": "d0fb6d67"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "def euclidean_distances_jax(\n",
        "    query_points: jnp.ndarray, dataset: jnp.ndarray\n",
        ") -> jnp.ndarray:\n",
        "    \"\"\"\n",
        "    Calculates the Euclidean distance between a set of query points and a dataset of points.\n",
        "\n",
        "    Args:\n",
        "        query_points (jnp.ndarray): Array of shape (n_queries, n_features).\n",
        "        dataset (jnp.ndarray): Array of shape (n_samples, n_features).\n",
        "\n",
        "    Returns:\n",
        "        jnp.ndarray: The Euclidean distance between the query points and the dataset.\n",
        "    \"\"\"\n",
        "    # Broadcasting (dataset - query_point) subtracts query_point from each row of dataset\n",
        "    return jnp.sqrt(jnp.sum((dataset[:, jnp.newaxis, :] - query_points) ** 2, axis=-1))\n",
        "\n",
        "\n",
        "euclidean_distances_jax_jit = jax.jit(euclidean_distances_jax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0821e3a",
      "metadata": {
        "id": "f0821e3a"
      },
      "outputs": [],
      "source": [
        "n_dataset_points: int = 10_000\n",
        "n_query_points: int = 100\n",
        "n_dim: int = 3\n",
        "k: int = 5\n",
        "\n",
        "\n",
        "dataset = create_random_data(n_dataset_points, n_dim, seed=420)\n",
        "query_points = create_random_data(n_query_points, n_dim, seed=421)\n",
        "\n",
        "dataset_jax = jnp.array(dataset)\n",
        "query_points_jax = jnp.array(query_points)\n",
        "\n",
        "np.testing.assert_allclose(euclidean_distances_numpy(query_points, dataset), euclidean_distances_jax(query_points_jax, dataset_jax))\n",
        "np.testing.assert_allclose(euclidean_distances_numpy(query_points, dataset), euclidean_distances_jax_jit(query_points_jax, dataset_jax), rtol=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35b7a6a",
      "metadata": {
        "id": "c35b7a6a"
      },
      "outputs": [],
      "source": [
        "%timeit euclidean_distances_numpy(query_points, dataset)\n",
        "%timeit euclidean_distances_jax(query_points_jax, dataset_jax).block_until_ready()\n",
        "%timeit euclidean_distances_jax_jit(query_points_jax, dataset_jax).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a68b689",
      "metadata": {
        "id": "1a68b689"
      },
      "outputs": [],
      "source": [
        "euclidean_execution_times = []\n",
        "euclidean_distances_jax_jit.__name__ = \"euclidean_distances_jax_jit\"\n",
        "\n",
        "for function in [euclidean_distances_numpy, euclidean_distances_jax, euclidean_distances_jax_jit]:\n",
        "    for n_dim in [2, 4]:\n",
        "        dataset = create_random_data(n_dataset_points, n_dim)\n",
        "        for n_query_points in [1, 100, 1_000, 10_000]:\n",
        "            query_points = create_random_data(n_query_points, n_dim)\n",
        "            if \"numpy\" in function.__name__:\n",
        "                execution_time = %timeit -o function(query_points, dataset)\n",
        "            else:\n",
        "                function(query_points, dataset).block_until_ready()\n",
        "                execution_time = %timeit -o function(query_points, dataset).block_until_ready()\n",
        "            euclidean_execution_times.append(\n",
        "                {\n",
        "                    \"n_query_points\": n_query_points,\n",
        "                    \"n_dataset_points\": n_dataset_points,\n",
        "                    \"n_dim\": n_dim,\n",
        "                    \"execution_time\": execution_time.average,\n",
        "                    \"function\": function.__name__,\n",
        "                }\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ac0fcb7",
      "metadata": {
        "id": "8ac0fcb7"
      },
      "outputs": [],
      "source": [
        "px.line(\n",
        "    euclidean_execution_times,\n",
        "    x=\"n_query_points\",\n",
        "    y=\"execution_time\",\n",
        "    title=\"Execution Time: Euclidean Distance\",\n",
        "    labels={\"n_query_points\": \"Number of Query Points\", \"execution_time\": \"Execution Time (s)\"},\n",
        "    log_x=True,\n",
        "    log_y=True,\n",
        "    markers=True,\n",
        "    color=\"function\",\n",
        "    facet_row=\"n_dim\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f67d5a5f",
      "metadata": {
        "id": "f67d5a5f"
      },
      "source": [
        "## Numba JIT compilation\n",
        "\n",
        "### What is Numba?\n",
        "\n",
        "[Numba documantaion](https://numba.pydata.org) says:\n",
        "> Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code.\n",
        "\n",
        "- Numba is a powerful just-in-time (JIT) compiler for Python that specialises in accelerating numerical and scientific computations.\n",
        "- It compiles Python functions to optimised machine code at runtime, dramatically speeding up array operations and mathematical algorithms.\n",
        "- This often allows us to achieve near C-level speeds for data science tasks, while maintaining the readability and flexibility of Python.\n",
        "\n",
        "### Differences between Numba and JAX\n",
        "\n",
        "- Numba does not need to recompile for a different input shape.\n",
        "- Numba works with numpy arrays directly.\n",
        "- Numba often requires the code to be written in a specific way, typically using loops.\n",
        "- Numba does not provide automatic differentiation.\n",
        "- GPU programming in Numba is more granular, lower level.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05509c00",
      "metadata": {
        "id": "05509c00"
      },
      "source": [
        "### Simple example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02a026a",
      "metadata": {
        "id": "e02a026a"
      },
      "outputs": [],
      "source": [
        "import numba\n",
        "\n",
        "x = np.arange(100).reshape(10, 10)\n",
        "\n",
        "def go_fast(a: np.ndarray) -> np.ndarray: # Function is compiled to machine code when called the first time\n",
        "    trace = 0.0\n",
        "    for i in range(a.shape[0]):   # Numba likes loops\n",
        "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
        "    return a + trace              # Numba likes NumPy broadcasting\n",
        "\n",
        "go_fast_jit = numba.jit(go_fast)\n",
        "\n",
        "print(go_fast_jit(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d30ac302",
      "metadata": {
        "id": "d30ac302"
      },
      "outputs": [],
      "source": [
        "%timeit go_fast(x)\n",
        "%timeit go_fast_jit(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f2c9fe",
      "metadata": {
        "id": "05f2c9fe"
      },
      "source": [
        "Important in our context:\n",
        "\n",
        "- Numpy arrays don't need to be converted to a different type.\n",
        "- Numba \"likes loops\" - we may need to rewrite the code to use loops instead of vectorised operations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9158e7fd",
      "metadata": {
        "id": "9158e7fd"
      },
      "source": [
        "### Exercise: Numba JIT compilation\n",
        "\n",
        "1. Create a Numba JIT-compiled version of the Euclidean distance function `euclidean_distances_numpy`.\n",
        "2. Verify that the JIT-compiled version yields the same result as the numpy version.\n",
        "3. Compare the performance of the numpy version, and the uncompiled and compiled numba version.\n",
        "4. Check that JIT does not depend on the input shape by comparing the performance on a `[:-1¨]` slice of the input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2200d1da",
      "metadata": {
        "id": "2200d1da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4de51edd",
      "metadata": {
        "id": "4de51edd"
      },
      "source": [
        "### Numba performance tuning\n",
        "\n",
        "The following are important options and techniques for optimising Numba code, as summarised from the official [Numba performance tips](https://numba.readthedocs.io/en/stable/user/performance-tips.html):\n",
        "\n",
        "1. Use `@numba.njit` (no Python mode):\n",
        "   - Prefer `@numba.njit` (or `@numba.jit(nopython=True)`) to ensure code is compiled in \"nopython\" mode, avoiding the Python interpreter for maximum speed.\n",
        "\n",
        "2. Enable parallel execution:\n",
        "   - Use `parallel=True` in the decorator (e.g., `@numba.njit(parallel=True)`) to allow Numba to automatically parallelise supported loops using `numba.prange`.\n",
        "   - Replace `range` with `numba.prange` in outer loops to enable parallelism.\n",
        "\n",
        "3. Enable fast math optimisations:\n",
        "   - Use `fastmath=True` to allow the compiler to apply aggressive floating-point optimisations, potentially sacrificing some numerical precision for speed.\n",
        "   - Example: `@numba.njit(fastmath=True)`\n",
        "\n",
        "4. Prefer simple, explicit loops:\n",
        "   - Numba excels with explicit for-loops and simple array operations.\n",
        "   - Avoid complex Python features, object arrays, or unsupported NumPy functions.\n",
        "\n",
        "5. Minimise Python object usage:\n",
        "   - Use NumPy arrays and primitive types; avoid lists of objects or dictionaries inside JIT-compiled functions.\n",
        "\n",
        "6. Preallocate arrays:\n",
        "   - Allocate output arrays before entering loops to avoid dynamic resizing, which is slow and not supported in nopython mode.\n",
        "\n",
        "7. Use supported NumPy functions:\n",
        "   - Stick to NumPy functions and methods that are supported by Numba for best performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "394fe50c",
      "metadata": {
        "id": "394fe50c"
      },
      "source": [
        "### Exercise: Numba performance tuning\n",
        "\n",
        "1. First, try `njit`, `fastmath=True`, and `parallel=True` on the `euclidean_distances_numpy` function. Measure the performance.\n",
        "2. Try the same options on the `euclidean_distances_numba_optimised` defined below. Compare the performance to the previous versions.\n",
        "3. Try to optimise the `euclidean_distances_numba_optimised` for `parallel=True` compilation.\n",
        "\n",
        "```python\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2dd9060",
      "metadata": {
        "id": "f2dd9060"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2f16e98b",
      "metadata": {
        "id": "2f16e98b"
      },
      "source": [
        "## JAX on GPU\n",
        "\n",
        "Open the [03-jax-gpu.ipynb](https://colab.research.google.com/github/coobas/europython-25/blob/main/03-jax-gpu.ipynb) notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37565350",
      "metadata": {
        "id": "37565350"
      },
      "source": [
        "## Further optimisation of the kNN search function\n",
        "\n",
        "So far we focused on the distance computation. This was more important as that calculation is the most time-consuming part of the kNN search. However, let's also try to optimise the nearest neighbour search, i.e. `knn_search_numpy`.\n",
        "\n",
        "- We can still get some speed-up by using JIT compilation.\n",
        "- We can avoind possible memory costly data copies between numpy and jax arrays.\n",
        "- And we can possibly run everything on GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70ac4623",
      "metadata": {
        "id": "70ac4623"
      },
      "source": [
        "### Exercise: JIT compilation of `knn_search_numpy`\n",
        "\n",
        "1. Create a JIT-compiled version of `knn_search_numpy`.\n",
        "2. Compare the performance of the JIT-compiled version to the original version.\n",
        "3. Verify the outputs of the JIT-compiled version match the outputs of `knn_search_numpy`. Note that the order of the indices does not matter.\n",
        "4. Try to run it on GPU and compare the performance.\n",
        "\n",
        "*Hints:* You will most likely run into issues. Look into how `static_argnames` parameter of `jax.jit` works. You will also need to replace `np.argpartition`: there are alternatives either in `numpy` or in `jax.lax`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2e522e",
      "metadata": {
        "id": "1b2e522e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e92c8e3a",
      "metadata": {
        "id": "e92c8e3a"
      },
      "source": [
        "## JAX vmap\n",
        "\n",
        "`vmap` (vectorising map) is JAX's automatic vectorisation transformation that allows you to apply functions designed for single inputs to batches of inputs efficiently.\n",
        "\n",
        "- Transforms functions that work on single values to work on batches without manual loop writing or vectorisation.\n",
        "- Generates efficient vectorised code that can leverage SIMD instructions and GPU parallelism.\n",
        "- Automatically handles broadcasting and dimension management across batch dimensions.\n",
        "- Can be combined with other JAX transformations like `jit`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1cc363e",
      "metadata": {
        "id": "e1cc363e"
      },
      "source": [
        "### `vmap` example\n",
        "\n",
        "Let's take a simple function `sum_of_squares`, defined as $f(x) = \\sum_{i=1}^n x_i^2$.\n",
        "\n",
        "First, we implement the function in a way that it expects a single vector as an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2dd7079",
      "metadata": {
        "id": "c2dd7079"
      },
      "outputs": [],
      "source": [
        "def sum_of_squares(vector: ArrayLike) -> jax.Array:\n",
        "  # This function expects a 1D array (vector)\n",
        "  print(f\"Running sum_of_squares for a vector of shape: {vector.shape}\")\n",
        "  return jnp.sum(vector**2)\n",
        "\n",
        "# Example single vector\n",
        "single_vector = jnp.array([1., 2., 3.])\n",
        "result_single = sum_of_squares(single_vector)\n",
        "print(f\"Result for single vector: {result_single}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac699fc",
      "metadata": {
        "id": "fac699fc"
      },
      "source": [
        "What if we now want to compute the sum of squares for a batch of vectors? Let's try to just execute the function for a batch of vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58f19202",
      "metadata": {
        "id": "58f19202"
      },
      "outputs": [],
      "source": [
        "batch_of_vectors = jnp.array([\n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.],\n",
        "    [7., 8., 9.],\n",
        "    [0., 1., 0.]\n",
        "])\n",
        "\n",
        "sum_of_squares(batch_of_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "694968ef",
      "metadata": {
        "id": "694968ef"
      },
      "source": [
        "This is not what we wanted! We actually needed to calculate the result for each vector in the batch. We could just loop but that would most likely be slow.\n",
        "\n",
        "Luckily, JAX provides a way to do this automatically. We can use the `vmap` function to vectorise the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d85f677e",
      "metadata": {
        "id": "d85f677e"
      },
      "outputs": [],
      "source": [
        "vectorized_sum_of_squares = jax.vmap(sum_of_squares)\n",
        "\n",
        "vectorized_sum_of_squares(batch_of_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30bae5a4",
      "metadata": {
        "id": "30bae5a4"
      },
      "source": [
        "### Exercise: Use `vmap` to vectorise the Euclidean distance calculation\n",
        "\n",
        "We defined `euclidean_distances_numpy` and `euclidean_distances_jax` already in a vectorised way. This was possible thanks to the broadcasting of numpy arrays.\n",
        "\n",
        "In this exercise, let's start from a simple `distance_scalar` function, which works on two vectors.\n",
        "The goal is to vectorise it using `vmap`, so that `x` and `y` can be `(m, n_dim)` and `(n, n_dim)` arrays.\n",
        "The result should be a `(m, n)` array. This is exactly the same behaviour as in `euclidean_distances_numpy` and `euclidean_distances_jax`.\n",
        "\n",
        "*Hints:* You will need to use `in_axes` parameter of `vmap`. You may need to use `vmap` twice.\n",
        "\n",
        "Optionally, compare the performance of the vmap version to the `euclidean_distances_jax` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a32e74",
      "metadata": {
        "id": "37a32e74"
      },
      "outputs": [],
      "source": [
        "# Use this function to start with\n",
        "def distance_scalar(x: jnp.ndarray, y: jnp.ndarray) -> jnp.ndarray:\n",
        "    return jnp.sqrt(jnp.sum((x - y)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e27661cb",
      "metadata": {
        "id": "e27661cb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}